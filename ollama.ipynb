{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJQ7Cay2XebEF2uqI5/M0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koji/GoogleColab/blob/main/ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beVKo0kHrfu9",
        "outputId": "dd44f83f-9383-4cb0-f4b6-317f9a93f5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\n",
            "100 10091    0 10091    0     0  36037      0 --:--:-- --:--:-- --:--:-- 36039\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 229 kB in 1s (158 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-12 cuda-drivers-550 dctrl-tools dkms fakeroot gcc-12\n",
            "  keyboard-configuration libasan8 libfakeroot libfontenc1 libgcc-12-dev\n",
            "  libjansson4 liblocale-gettext-perl libnvidia-cfg1-550 libnvidia-common-550\n",
            "  libnvidia-compute-550 libnvidia-decode-550 libnvidia-encode-550\n",
            "  libnvidia-extra-550 libnvidia-fbc1-550 libnvidia-gl-550 libtsan2 libudev1\n",
            "  libxcvt0 libxfont2 libxkbfile1 nvidia-compute-utils-550 nvidia-dkms-550\n",
            "  nvidia-driver-550 nvidia-firmware-550-550.54.15 nvidia-kernel-common-550\n",
            "  nvidia-kernel-source-550 nvidia-prime nvidia-settings nvidia-utils-550\n",
            "  python3-xkit screen-resolution-extra systemd-hwe-hwdb udev x11-xkb-utils\n",
            "  xcvt xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "  xserver-xorg-core xserver-xorg-video-nvidia-550\n",
            "Suggested packages:\n",
            "  gcc-12-locales cpp-12-doc debtags menu gcc-12-multilib gcc-12-doc xfs\n",
            "  | xserver xfonts-100dpi | xfonts-75dpi xfonts-scalable\n",
            "Recommended packages:\n",
            "  libnvidia-compute-550:i386 libnvidia-decode-550:i386\n",
            "  libnvidia-encode-550:i386 libnvidia-fbc1-550:i386 libnvidia-gl-550:i386\n",
            "The following NEW packages will be installed:\n",
            "  cpp-12 cuda-drivers cuda-drivers-550 dctrl-tools dkms fakeroot gcc-12\n",
            "  keyboard-configuration libasan8 libfakeroot libfontenc1 libgcc-12-dev\n",
            "  libjansson4 liblocale-gettext-perl libnvidia-cfg1-550 libnvidia-common-550\n",
            "  libnvidia-compute-550 libnvidia-decode-550 libnvidia-encode-550\n",
            "  libnvidia-extra-550 libnvidia-fbc1-550 libnvidia-gl-550 libtsan2 libxcvt0\n",
            "  libxfont2 libxkbfile1 nvidia-compute-utils-550 nvidia-dkms-550\n",
            "  nvidia-driver-550 nvidia-firmware-550-550.54.15 nvidia-kernel-common-550\n",
            "  nvidia-kernel-source-550 nvidia-prime nvidia-settings nvidia-utils-550\n",
            "  python3-xkit screen-resolution-extra systemd-hwe-hwdb udev x11-xkb-utils\n",
            "  xcvt xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "  xserver-xorg-core xserver-xorg-video-nvidia-550\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 47 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 320 MB of archives.\n",
            "After this operation, 885 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblocale-gettext-perl amd64 1.07-4build3 [17.1 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-common-550 550.54.15-0ubuntu1 [17.1 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-550 550.54.15-0ubuntu1 [49.5 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 keyboard-configuration all 1.205ubuntu3 [206 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-gl-550 550.54.15-0ubuntu1 [136 MB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 dctrl-tools amd64 2.24-3build2 [66.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dkms all 2.8.7-2ubuntu2.2 [70.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjansson4 amd64 2.13.1-1.1build3 [32.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcvt0 amd64 0.1.1-3 [5,494 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-xorg-core amd64 2:21.1.4-2ubuntu1.7~22.04.10 [1,476 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfakeroot amd64 1.28-1ubuntu1 [31.5 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 fakeroot amd64 1.28-1ubuntu1 [60.4 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 nvidia-prime all 0.8.17.1 [9,956 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-xkit all 0.5.0ubuntu5 [18.5 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 screen-resolution-extra all 0.18.2 [4,396 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 xcvt amd64 0.1.1-3 [7,140 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-source-550 550.54.15-0ubuntu1 [41.1 MB]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-firmware-550-550.54.15 550.54.15-0ubuntu1 [36.8 MB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-kernel-common-550 550.54.15-0ubuntu1 [109 kB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-dkms-550 550.54.15-0ubuntu1 [36.2 kB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-extra-550 550.54.15-0ubuntu1 [71.1 kB]\n",
            "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-compute-utils-550 550.54.15-0ubuntu1 [118 kB]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-decode-550 550.54.15-0ubuntu1 [1,783 kB]\n",
            "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-encode-550 550.54.15-0ubuntu1 [100 kB]\n",
            "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-utils-550 550.54.15-0ubuntu1 [494 kB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-cfg1-550 550.54.15-0ubuntu1 [145 kB]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  xserver-xorg-video-nvidia-550 550.54.15-0ubuntu1 [1,534 kB]\n",
            "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-fbc1-550 550.54.15-0ubuntu1 [54.9 kB]\n",
            "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-driver-550 550.54.15-0ubuntu1 [489 kB]\n",
            "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers-550 550.54.15-1 [2,542 B]\n",
            "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-drivers 550.54.15-1 [2,502 B]\n",
            "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nvidia-settings 550.54.15-0ubuntu1 [947 kB]\n",
            "Fetched 320 MB in 5s (69.1 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package liblocale-gettext-perl.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../0-liblocale-gettext-perl_1.07-4build3_amd64.deb ...\n",
            "Unpacking liblocale-gettext-perl (1.07-4build3) ...\n",
            "Selecting previously unselected package keyboard-configuration.\n",
            "Preparing to unpack .../1-keyboard-configuration_1.205ubuntu3_all.deb ...\n",
            "Unpacking keyboard-configuration (1.205ubuntu3) ...\n",
            "Selecting previously unselected package cpp-12.\n",
            "Preparing to unpack .../2-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libasan8:amd64.\n",
            "Preparing to unpack .../3-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libtsan2:amd64.\n",
            "Preparing to unpack .../4-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libgcc-12-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package gcc-12.\n",
            "Preparing to unpack .../6-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package dctrl-tools.\n",
            "Preparing to unpack .../7-dctrl-tools_2.24-3build2_amd64.deb ...\n",
            "Unpacking dctrl-tools (2.24-3build2) ...\n",
            "Selecting previously unselected package dkms.\n",
            "Preparing to unpack .../8-dkms_2.8.7-2ubuntu2.2_all.deb ...\n",
            "Unpacking dkms (2.8.7-2ubuntu2.2) ...\n",
            "Preparing to unpack .../9-libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 122278 files and directories currently installed.)\n",
            "Preparing to unpack .../00-udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libjansson4:amd64.\n",
            "Preparing to unpack .../01-libjansson4_2.13.1-1.1build3_amd64.deb ...\n",
            "Unpacking libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Selecting previously unselected package libnvidia-common-550.\n",
            "Preparing to unpack .../02-libnvidia-common-550_550.54.15-0ubuntu1_all.deb ...\n",
            "Unpacking libnvidia-common-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-550:amd64.\n",
            "Preparing to unpack .../03-libnvidia-compute-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-gl-550:amd64.\n",
            "Preparing to unpack .../04-libnvidia-gl-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "dpkg-query: no packages found matching libnvidia-gl-535\n",
            "Unpacking libnvidia-gl-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-source-550.\n",
            "Preparing to unpack .../05-nvidia-kernel-source-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-source-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-firmware-550-550.54.15.\n",
            "Preparing to unpack .../06-nvidia-firmware-550-550.54.15_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-firmware-550-550.54.15 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-kernel-common-550.\n",
            "Preparing to unpack .../07-nvidia-kernel-common-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-kernel-common-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-dkms-550.\n",
            "Preparing to unpack .../08-nvidia-dkms-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-dkms-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-extra-550:amd64.\n",
            "Preparing to unpack .../09-libnvidia-extra-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-extra-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-compute-utils-550.\n",
            "Preparing to unpack .../10-nvidia-compute-utils-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-compute-utils-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-decode-550:amd64.\n",
            "Preparing to unpack .../11-libnvidia-decode-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-decode-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-encode-550:amd64.\n",
            "Preparing to unpack .../12-libnvidia-encode-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-encode-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-utils-550.\n",
            "Preparing to unpack .../13-nvidia-utils-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-utils-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-cfg1-550:amd64.\n",
            "Preparing to unpack .../14-libnvidia-cfg1-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-cfg1-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../15-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../16-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../17-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package libxcvt0:amd64.\n",
            "Preparing to unpack .../18-libxcvt0_0.1.1-3_amd64.deb ...\n",
            "Unpacking libxcvt0:amd64 (0.1.1-3) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../19-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../20-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package xserver-xorg-core.\n",
            "Preparing to unpack .../21-xserver-xorg-core_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xserver-xorg-video-nvidia-550.\n",
            "Preparing to unpack .../22-xserver-xorg-video-nvidia-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking xserver-xorg-video-nvidia-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-fbc1-550:amd64.\n",
            "Preparing to unpack .../23-libnvidia-fbc1-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-fbc1-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-driver-550.\n",
            "Preparing to unpack .../24-nvidia-driver-550_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-driver-550 (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package cuda-drivers-550.\n",
            "Preparing to unpack .../25-cuda-drivers-550_550.54.15-1_amd64.deb ...\n",
            "Unpacking cuda-drivers-550 (550.54.15-1) ...\n",
            "Selecting previously unselected package cuda-drivers.\n",
            "Preparing to unpack .../26-cuda-drivers_550.54.15-1_amd64.deb ...\n",
            "Unpacking cuda-drivers (550.54.15-1) ...\n",
            "Selecting previously unselected package libfakeroot:amd64.\n",
            "Preparing to unpack .../27-libfakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package fakeroot.\n",
            "Preparing to unpack .../28-fakeroot_1.28-1ubuntu1_amd64.deb ...\n",
            "Unpacking fakeroot (1.28-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-prime.\n",
            "Preparing to unpack .../29-nvidia-prime_0.8.17.1_all.deb ...\n",
            "Unpacking nvidia-prime (0.8.17.1) ...\n",
            "Selecting previously unselected package python3-xkit.\n",
            "Preparing to unpack .../30-python3-xkit_0.5.0ubuntu5_all.deb ...\n",
            "Unpacking python3-xkit (0.5.0ubuntu5) ...\n",
            "Selecting previously unselected package screen-resolution-extra.\n",
            "Preparing to unpack .../31-screen-resolution-extra_0.18.2_all.deb ...\n",
            "Unpacking screen-resolution-extra (0.18.2) ...\n",
            "Selecting previously unselected package nvidia-settings.\n",
            "Preparing to unpack .../32-nvidia-settings_550.54.15-0ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-settings (550.54.15-0ubuntu1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../33-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package xcvt.\n",
            "Preparing to unpack .../34-xcvt_0.1.1-3_amd64.deb ...\n",
            "Unpacking xcvt (0.1.1-3) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../35-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../36-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../37-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libnvidia-compute-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up nvidia-prime (0.8.17.1) ...\n",
            "Setting up libnvidia-common-550 (550.54.15-0ubuntu1) ...\n",
            "Setting up nvidia-firmware-550-550.54.15 (550.54.15-0ubuntu1) ...\n",
            "Setting up nvidia-utils-550 (550.54.15-0ubuntu1) ...\n",
            "Setting up libnvidia-fbc1-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up libnvidia-cfg1-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up nvidia-compute-utils-550 (550.54.15-0ubuntu1) ...\n",
            "Warning: The home dir /nonexistent you specified can't be accessed: No such file or directory\n",
            "Adding system user `nvidia-persistenced' (UID 104) ...\n",
            "Adding new group `nvidia-persistenced' (GID 107) ...\n",
            "Adding new user `nvidia-persistenced' (UID 104) with group `nvidia-persistenced' ...\n",
            "Not creating home directory `/nonexistent'.\n",
            "Setting up libfakeroot:amd64 (1.28-1ubuntu1) ...\n",
            "Setting up libjansson4:amd64 (2.13.1-1.1build3) ...\n",
            "Setting up fakeroot (1.28-1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libnvidia-gl-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up nvidia-kernel-common-550 (550.54.15-0ubuntu1) ...\n",
            "Created symlink /etc/systemd/system/systemd-hibernate.service.wants/nvidia-hibernate.service → /lib/systemd/system/nvidia-hibernate.service.\n",
            "Created symlink /etc/systemd/system/systemd-suspend.service.wants/nvidia-resume.service → /lib/systemd/system/nvidia-resume.service.\n",
            "Created symlink /etc/systemd/system/systemd-hibernate.service.wants/nvidia-resume.service → /lib/systemd/system/nvidia-resume.service.\n",
            "Created symlink /etc/systemd/system/systemd-suspend.service.wants/nvidia-suspend.service → /lib/systemd/system/nvidia-suspend.service.\n",
            "Setting up libnvidia-extra-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libxcvt0:amd64 (0.1.1-3) ...\n",
            "Setting up nvidia-kernel-source-550 (550.54.15-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up python3-xkit (0.5.0ubuntu5) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up liblocale-gettext-perl (1.07-4build3) ...\n",
            "Setting up dctrl-tools (2.24-3build2) ...\n",
            "Setting up libnvidia-decode-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libnvidia-encode-550:amd64 (550.54.15-0ubuntu1) ...\n",
            "Setting up xcvt (0.1.1-3) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up screen-resolution-extra (0.18.2) ...\n",
            "Setting up nvidia-settings (550.54.15-0ubuntu1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up keyboard-configuration (1.205ubuntu3) ...\n",
            "Your console font configuration will be updated the next time your system\n",
            "boots. If you want to update it now, run 'setupcon' from a virtual console.\n",
            "Setting up xserver-xorg-core (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up xserver-xorg-video-nvidia-550 (550.54.15-0ubuntu1) ...\n",
            "Setting up dkms (2.8.7-2ubuntu2.2) ...\n",
            "Setting up nvidia-dkms-550 (550.54.15-0ubuntu1) ...\n",
            "Loading new nvidia-550.54.15 DKMS files...\n",
            "It is likely that 6.1.58+ belongs to a chroot's host\n",
            "Building for 5.15.0-107-generic\n",
            "Building for architecture x86_64\n",
            "Building initial module for 5.15.0-107-generic\n",
            "Done.\n",
            "\n",
            "nvidia.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-107-generic/updates/dkms/\n",
            "\n",
            "nvidia-modeset.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-107-generic/updates/dkms/\n",
            "\n",
            "nvidia-drm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-107-generic/updates/dkms/\n",
            "\n",
            "nvidia-uvm.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-107-generic/updates/dkms/\n",
            "\n",
            "nvidia-peermem.ko:\n",
            "Running module version sanity check.\n",
            " - Original module\n",
            "   - No original module exists within this kernel\n",
            " - Installation\n",
            "   - Installing to /lib/modules/5.15.0-107-generic/updates/dkms/\n",
            "\n",
            "depmod...\n",
            "Setting up nvidia-driver-550 (550.54.15-0ubuntu1) ...\n",
            "Setting up cuda-drivers-550 (550.54.15-1) ...\n",
            "Setting up cuda-drivers (550.54.15-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
        "!sudo apt-get update && sudo apt-get install -y cuda-drivers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "os.environ.update({'OLLAMA_HOST': '0.0.0.0'})"
      ],
      "metadata": {
        "id": "5tA2owldrwib"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuaE7ndjr1L7",
        "outputId": "c7ae514c-782f-43c1-9597-65b9f2764edc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-15 00:43:26--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2024.4.1/cloudflared-linux-amd64.deb [following]\n",
            "--2024-05-15 00:43:26--  https://github.com/cloudflare/cloudflared/releases/download/2024.4.1/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/974cbcb3-672c-4a16-ab31-ee17813c8510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240515%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240515T004326Z&X-Amz-Expires=300&X-Amz-Signature=037b3fc1e4bdf6fe16ea51e3d8a8324f207bfcc3c9c5f4863537fedf068bd909&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-15 00:43:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/974cbcb3-672c-4a16-ab31-ee17813c8510?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240515%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240515T004326Z&X-Amz-Expires=300&X-Amz-Signature=037b3fc1e4bdf6fe16ea51e3d8a8324f207bfcc3c9c5f4863537fedf068bd909&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17786268 (17M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  16.96M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-05-15 00:43:26 (125 MB/s) - ‘cloudflared-linux-amd64.deb’ saved [17786268/17786268]\n",
            "\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 123835 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2024.4.1) ...\n",
            "Setting up cloudflared (2024.4.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "\n",
        "    p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    for line in p.stderr:\n",
        "        l = line.decode()\n",
        "        if \"trycloudflare.com \" in l:\n",
        "            print(\"\\n\\n\\n\\n\\n\")\n",
        "            print(\"running ollama server\\n\\n\", l[l.find(\"http\"):], end='')\n",
        "            print(\"\\n\\n\\n\\n\\n\")\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(11434,)).start()"
      ],
      "metadata": {
        "id": "99JwU7Lqr5BR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama serve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOTJ5SoMr_2d",
        "outputId": "d836679e-e06d-498c-f2bb-2c57a2c2f2f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
            "Your new public key is: \n",
            "\n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPP7rDroN/K9kcOG07j4dPl511d2CvLN2e596OGI0X2+\n",
            "\n",
            "2024/05/15 00:43:28 routes.go:1006: INFO server config env=\"map[OLLAMA_DEBUG:false OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]\"\n",
            "time=2024-05-15T00:43:28.015Z level=INFO source=images.go:704 msg=\"total blobs: 0\"\n",
            "time=2024-05-15T00:43:28.015Z level=INFO source=images.go:711 msg=\"total unused blobs removed: 0\"\n",
            "time=2024-05-15T00:43:28.016Z level=INFO source=routes.go:1052 msg=\"Listening on [::]:11434 (version 0.1.37)\"\n",
            "time=2024-05-15T00:43:28.016Z level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama1488007954/runners\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "running ollama server\n",
            "\n",
            " https://rf-longest-narrative-correctly.trycloudflare.com                                  |\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "time=2024-05-15T00:43:33.653Z level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu_avx2 cuda_v11 rocm_v60002 cpu cpu_avx]\"\n",
            "time=2024-05-15T00:43:34.006Z level=INFO source=types.go:71 msg=\"inference compute\" id=GPU-4ec0312f-0fa1-ebe9-0740-99596751cf8a library=cuda compute=7.5 driver=12.2 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n",
            "[GIN] 2024/05/15 - 00:45:56 |\u001b[90;43m 404 \u001b[0m|      22.041µs |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"//api/pull\"\n",
            "time=2024-05-15T00:46:47.648Z level=INFO source=download.go:136 msg=\"downloading 3f75702e9f27 in 64 103 MB part(s)\"\n",
            "time=2024-05-15T00:47:29.528Z level=INFO source=download.go:136 msg=\"downloading 4fa551d4f938 in 1 12 KB part(s)\"\n",
            "time=2024-05-15T00:47:31.378Z level=INFO source=download.go:136 msg=\"downloading 8ab4849b038c in 1 254 B part(s)\"\n",
            "time=2024-05-15T00:47:33.178Z level=INFO source=download.go:136 msg=\"downloading 577073ffcc6c in 1 110 B part(s)\"\n",
            "time=2024-05-15T00:47:35.052Z level=INFO source=download.go:136 msg=\"downloading 2b6d5e4fb7d2 in 1 483 B part(s)\"\n",
            "[GIN] 2024/05/15 - 00:48:13 |\u001b[97;42m 200 \u001b[0m|         1m27s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/pull\"\n",
            "time=2024-05-15T00:49:37.459Z level=INFO source=memory.go:127 msg=\"offload to gpu\" layers.real=-1 layers.estimate=33 memory.available=\"14.6 GiB\" memory.required.full=\"6.8 GiB\" memory.required.partial=\"6.8 GiB\" memory.required.kv=\"256.0 MiB\" memory.weights.total=\"5.9 GiB\" memory.weights.repeating=\"5.5 GiB\" memory.weights.nonrepeating=\"411.0 MiB\" memory.graph.full=\"164.0 MiB\" memory.graph.partial=\"677.5 MiB\"\n",
            "time=2024-05-15T00:49:37.459Z level=INFO source=memory.go:127 msg=\"offload to gpu\" layers.real=-1 layers.estimate=33 memory.available=\"14.6 GiB\" memory.required.full=\"6.8 GiB\" memory.required.partial=\"6.8 GiB\" memory.required.kv=\"256.0 MiB\" memory.weights.total=\"5.9 GiB\" memory.weights.repeating=\"5.5 GiB\" memory.weights.nonrepeating=\"411.0 MiB\" memory.graph.full=\"164.0 MiB\" memory.graph.partial=\"677.5 MiB\"\n",
            "time=2024-05-15T00:49:37.460Z level=INFO source=server.go:318 msg=\"starting llama server\" cmd=\"/tmp/ollama1488007954/runners/cuda_v11/ollama_llama_server --model /root/.ollama/models/blobs/sha256-3f75702e9f27f9b481928f2df8e2c011ae9b27e18821edc48ce5953160a2cb93 --ctx-size 2048 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 1 --port 38637\"\n",
            "time=2024-05-15T00:49:37.461Z level=INFO source=sched.go:333 msg=\"loaded runners\" count=1\n",
            "time=2024-05-15T00:49:37.461Z level=INFO source=server.go:488 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-05-15T00:49:37.462Z level=INFO source=server.go:524 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=1 commit=\"952d03d\" tid=\"137984143007744\" timestamp=1715734177\n",
            "INFO [main] system info | n_threads=2 n_threads_batch=-1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"137984143007744\" timestamp=1715734177 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"3\" port=\"38637\" tid=\"137984143007744\" timestamp=1715734177\n",
            "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-3f75702e9f27f9b481928f2df8e2c011ae9b27e18821edc48ce5953160a2cb93 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "time=2024-05-15T00:49:37.716Z level=INFO source=server.go:524 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "llm_load_vocab: missing pre-tokenizer type, using: 'default'\n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "llm_load_vocab: CONSIDER REGENERATING THE MODEL             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q6_K\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
            "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   yes\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   410.98 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  5871.99 MiB\n",
            ".........................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 500000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.50 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    12.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"137984143007744\" timestamp=1715734209\n",
            "time=2024-05-15T00:50:09.603Z level=INFO source=server.go:529 msg=\"llama runner started in 32.14 seconds\"\n",
            "[GIN] 2024/05/15 - 00:50:28 |\u001b[97;42m 200 \u001b[0m| 52.284964505s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:51:10 |\u001b[97;42m 200 \u001b[0m|  13.19110057s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:51:53 |\u001b[97;41m 500 \u001b[0m|   6.00150303s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:52:14 |\u001b[97;42m 200 \u001b[0m| 14.735899532s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:52:49 |\u001b[97;42m 200 \u001b[0m| 20.003603769s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:55:21 |\u001b[97;42m 204 \u001b[0m|      32.467µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[90;47m OPTIONS \u001b[0m \"/api/chat/chat-stream\"\n",
            "[GIN] 2024/05/15 - 00:55:21 |\u001b[90;43m 404 \u001b[0m|       11.45µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat/chat-stream\"\n",
            "[GIN] 2024/05/15 - 00:57:23 |\u001b[90;43m 404 \u001b[0m|      39.773µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat/chat-stream\"\n",
            "[GIN] 2024/05/15 - 00:58:05 |\u001b[97;42m 204 \u001b[0m|       15.04µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[90;47m OPTIONS \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:58:05 |\u001b[90;43m 400 \u001b[0m|      85.059µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:58:49 |\u001b[90;43m 400 \u001b[0m|      81.975µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:58:51 |\u001b[90;43m 400 \u001b[0m|        78.3µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:58:53 |\u001b[90;43m 400 \u001b[0m|      78.134µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:58:53 |\u001b[90;43m 400 \u001b[0m|      59.047µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 00:59:33 |\u001b[97;42m 204 \u001b[0m|       13.37µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[90;47m OPTIONS \u001b[0m \"/api/chat-stream\"\n",
            "[GIN] 2024/05/15 - 00:59:33 |\u001b[90;43m 404 \u001b[0m|      10.677µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat-stream\"\n",
            "[GIN] 2024/05/15 - 00:59:34 |\u001b[90;43m 404 \u001b[0m|      12.058µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat-stream\"\n",
            "[GIN] 2024/05/15 - 01:00:42 |\u001b[90;43m 400 \u001b[0m|      99.356µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 01:03:29 |\u001b[90;43m 400 \u001b[0m|     128.312µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 01:03:33 |\u001b[90;43m 400 \u001b[0m|      83.826µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "[GIN] 2024/05/15 - 01:03:52 |\u001b[90;43m 400 \u001b[0m|      96.409µs | 2a09:bac5:a6f1:1973::289:15 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n",
            "time=2024-05-15T01:06:32.689Z level=INFO source=memory.go:127 msg=\"offload to gpu\" layers.real=-1 layers.estimate=33 memory.available=\"14.6 GiB\" memory.required.full=\"6.8 GiB\" memory.required.partial=\"6.8 GiB\" memory.required.kv=\"256.0 MiB\" memory.weights.total=\"5.9 GiB\" memory.weights.repeating=\"5.5 GiB\" memory.weights.nonrepeating=\"411.0 MiB\" memory.graph.full=\"164.0 MiB\" memory.graph.partial=\"677.5 MiB\"\n",
            "time=2024-05-15T01:06:32.689Z level=INFO source=memory.go:127 msg=\"offload to gpu\" layers.real=-1 layers.estimate=33 memory.available=\"14.6 GiB\" memory.required.full=\"6.8 GiB\" memory.required.partial=\"6.8 GiB\" memory.required.kv=\"256.0 MiB\" memory.weights.total=\"5.9 GiB\" memory.weights.repeating=\"5.5 GiB\" memory.weights.nonrepeating=\"411.0 MiB\" memory.graph.full=\"164.0 MiB\" memory.graph.partial=\"677.5 MiB\"\n",
            "time=2024-05-15T01:06:32.690Z level=INFO source=server.go:318 msg=\"starting llama server\" cmd=\"/tmp/ollama1488007954/runners/cuda_v11/ollama_llama_server --model /root/.ollama/models/blobs/sha256-3f75702e9f27f9b481928f2df8e2c011ae9b27e18821edc48ce5953160a2cb93 --ctx-size 2048 --batch-size 512 --embedding --log-disable --n-gpu-layers 33 --parallel 1 --port 38047\"\n",
            "time=2024-05-15T01:06:32.690Z level=INFO source=sched.go:333 msg=\"loaded runners\" count=1\n",
            "time=2024-05-15T01:06:32.690Z level=INFO source=server.go:488 msg=\"waiting for llama runner to start responding\"\n",
            "time=2024-05-15T01:06:32.690Z level=INFO source=server.go:524 msg=\"waiting for server to become available\" status=\"llm server error\"\n",
            "INFO [main] build info | build=1 commit=\"952d03d\" tid=\"140448334364672\" timestamp=1715735192\n",
            "INFO [main] system info | n_threads=2 n_threads_batch=-1 system_info=\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \" tid=\"140448334364672\" timestamp=1715735192 total_threads=2\n",
            "INFO [main] HTTP server listening | hostname=\"127.0.0.1\" n_threads_http=\"3\" port=\"38047\" tid=\"140448334364672\" timestamp=1715735192\n",
            "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from /root/.ollama/models/blobs/sha256-3f75702e9f27f9b481928f2df8e2c011ae9b27e18821edc48ce5953160a2cb93 (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "time=2024-05-15T01:06:32.941Z level=INFO source=server.go:524 msg=\"waiting for server to become available\" status=\"llm server loading model\"\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "llm_load_vocab: missing pre-tokenizer type, using: 'default'\n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "llm_load_vocab: CONSIDER REGENERATING THE MODEL             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q6_K\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
            "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   yes\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   410.98 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  5871.99 MiB\n",
            ".........................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 500000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.50 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   258.50 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    12.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "INFO [main] model loaded | tid=\"140448334364672\" timestamp=1715735199\n",
            "time=2024-05-15T01:06:39.971Z level=INFO source=server.go:529 msg=\"llama runner started in 7.28 seconds\"\n",
            "[GIN] 2024/05/15 - 01:06:58 |\u001b[97;42m 200 \u001b[0m|  27.32240691s |  104.28.204.175 |\u001b[97;46m POST    \u001b[0m \"/api/chat\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "98DiSGGNsAxg"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}